{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu7QawuvKQDN",
        "outputId": "1664df79-35b2-4a2b-d6f1-da665250a33b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FkR6zzE7Ibyq"
      },
      "outputs": [],
      "source": [
        "\n",
        "modelname =\"GB_MyModel_4ٍEsf__seed_pred 12_1_ep 17_seq 96\"\n",
        "model_weights_path = '/content/drive/MyDrive/Data_FFT_Model/MyModel_4Esfand1403/'+ modelname +'.pth'\n",
        "\n",
        "model_weights_path_1 = '/content/drive/MyDrive/Data_FFT_Model/MyModel_4Esfand1403_Result/'\n",
        "\n",
        "Result_name = modelname +'.txt'\n",
        "R_name_fig_price=\"price \"+modelname+\".png\"\n",
        "R_name_fig_load=\"load \"+ modelname + \".png\"\n",
        "\n",
        "pred_file = \"pred_\"+modelname+\".pt\"\n",
        "true_file= \"True_\"+modelname+\".pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZdC3e1IkdX"
      },
      "source": [
        "#imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6xCvTLG58di",
        "outputId": "819d5765-0d5b-4bee-9d3d-1a3a394d7d0c"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z2n9feS6MCZy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler,RobustScaler\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MwYGstJIy7n"
      },
      "source": [
        "#Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zKAOpWSw-KEX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5SZ6VPES-P4d"
      },
      "outputs": [],
      "source": [
        "config = dotdict()\n",
        "\n",
        "config.input_size = 6 #(month, day,hour , ...)\n",
        "config.output_size = 3\n",
        "\n",
        "config.hidden_size = 256 #256\n",
        "config.num_layers =2 #Agar 3 koni bayad be concat kardan akharesh ezafe koni\n",
        "\n",
        "config.seq_len = 96\n",
        "config.pred_len = 12\n",
        "\n",
        "config.learning_rate = 0.001\n",
        "\n",
        "config.batch_size = 32\n",
        "config.epochs = 200\n",
        "\n",
        "config.early_stopping = 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pElBTBtH-iAY"
      },
      "source": [
        "# Data\n",
        "### read, preprocess, split, scale, Create Daatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bjqrvcy2-eGs"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yin6U3bN-eDK",
        "outputId": "3caa9eff-1ce6-4e72-80a1-6d22536c5d71"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DpcC91QOI4ZR"
      },
      "outputs": [],
      "source": [
        "#----- for data_Load_Forecast\n",
        "\n",
        "def NEW_for_forecastRead_Data_cleaning():\n",
        "\n",
        "  data = pd.read_csv('/content/drive/MyDrive/Data_FFT_Model/GB_GBN_withoutTemp_Wind.csv')\n",
        "\n",
        "  data['date'] = pd.to_datetime(data.date)\n",
        "  data['year'] = data['date'].dt.year\n",
        "  data['month'] = data['date'].dt.month\n",
        "  data['day'] = data['date'].dt.day\n",
        "  data['hour'] = data['date'].dt.hour\n",
        "\n",
        "  data = data.drop('date', axis=1)\n",
        "  data = data.drop('year', axis=1)\n",
        "\n",
        "  threshold = 2\n",
        "  #Remove Noise and outliers\n",
        "  data =data[(data['Price']>0)] \n",
        "\n",
        "  print('---- data---- ', data.shape)\n",
        "\n",
        "\n",
        "  data = data.dropna(axis=0, how='any')\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dd1joQEVJ97L"
      },
      "outputs": [],
      "source": [
        "def Data_forecast_Split_Scales(data):\n",
        "  #split\n",
        "  train_size = int( len(data) * 0.8 )\n",
        "  test_size = len(data) - train_size\n",
        "  train, test = data[:train_size], data[train_size:]\n",
        "\n",
        "  print(test.shape)\n",
        "  scaler_test = StandardScaler()\n",
        "  test_sc = test.values\n",
        "\n",
        "\n",
        "  scaler = StandardScaler()#MinMaxScaler()#RobustScaler#ُ\n",
        "\n",
        "  return train, test , scaler_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJeEKlDDKXRR",
        "outputId": "3d6fd9c7-6c07-4749-f4e9-77971354f3e2"
      },
      "outputs": [],
      "source": [
        "# dataF , data_Load_Forecast = NEW_for_forecastRead_Data_cleaning()\n",
        "dataF = NEW_for_forecastRead_Data_cleaning()\n",
        "print('data_f = ' , dataF.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhYkzyjHKXRT",
        "outputId": "078ea694-5fd2-47f3-9975-1a4ebf021140"
      },
      "outputs": [],
      "source": [
        "train_data_F, test_dataF, scaler = Data_forecast_Split_Scales(dataF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "826wWqXikJ9w",
        "outputId": "416656f8-4f23-4609-b511-60de9198e720"
      },
      "outputs": [],
      "source": [
        "print(test_dataF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J7xLEXegxkYf"
      },
      "outputs": [],
      "source": [
        "def Data_Split_Scales(data):\n",
        "  #split\n",
        "  train_size = int( len(data) * 0.8 )\n",
        "  test_size = len(data) - train_size\n",
        "  train, test = data[:train_size], data[train_size:]\n",
        "\n",
        "  print(test.shape)\n",
        "  scaler_test = StandardScaler()\n",
        "  test_sc = test.values\n",
        "  scaler_test.fit(test_sc[:,0:config['output_size']])\n",
        "\n",
        "  scaler = StandardScaler()#MinMaxScaler()#RobustScaler#ُ\n",
        "\n",
        "  train = scaler.fit_transform(train.values)\n",
        "  test = scaler.fit_transform(test.values)\n",
        "\n",
        "  return train, test , scaler_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhLMG1h6Ai2T",
        "outputId": "97e1c938-ae23-401e-ca1e-12e933444964"
      },
      "outputs": [],
      "source": [
        "data  = NEW_for_forecastRead_Data_cleaning()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuEheTLaGh89",
        "outputId": "7f619e60-1350-426a-dbad-74bc839068b7"
      },
      "outputs": [],
      "source": [
        "train_data_, test_data, scaler = Data_Split_Scales(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I4auOqatmih4"
      },
      "outputs": [],
      "source": [
        "def MyCreate_dataset(data, seq_len, pred_len, pred_size, step):\n",
        "  x, y , forecast=[], [], []\n",
        "\n",
        "  for i in range(0, len(data) - seq_len - pred_len , step):\n",
        "    feature = data[i: i+seq_len]\n",
        "    target = data[i+seq_len: i+seq_len+pred_len]\n",
        "\n",
        "    target = target[:, 0:pred_size]\n",
        "\n",
        "\n",
        "    x.append(feature)\n",
        "    y.append(target)\n",
        "\n",
        "  return torch.tensor(x), torch.tensor(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2USHRalAwEig"
      },
      "source": [
        "#Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QRSm8822v9MC"
      },
      "outputs": [],
      "source": [
        "#Metrics\n",
        "import numpy as np\n",
        "\n",
        "def RSE(pred, true):\n",
        "    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\n",
        "\n",
        "def CORR(pred, true):\n",
        "    true = true.reshape(-1, 1)\n",
        "    pred = pred.reshape(-1, 1)\n",
        "    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n",
        "    d = np.sqrt(((true - true.mean(0)) ** 2).sum(0) * ((pred - pred.mean(0)) ** 2).sum(0))\n",
        "    return (u / d).mean()\n",
        "\n",
        "\n",
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "\n",
        "\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "\n",
        "\n",
        "def RMSE(pred, true):\n",
        "    return np.sqrt(MSE(pred, true))\n",
        "\n",
        "\n",
        "def MAPE(pred, true):\n",
        "    return np.mean(np.abs((pred - true) / true))\n",
        "\n",
        "\n",
        "def MSPE(pred, true):\n",
        "    return np.mean(np.square((pred - true) / true))\n",
        "\n",
        "\n",
        "def metric(pred, true):\n",
        "    mae = MAE(pred, true)\n",
        "    mse = MSE(pred, true)\n",
        "    rmse = RMSE(pred, true)\n",
        "    mape = MAPE(pred, true)\n",
        "    mspe = MSPE(pred, true)\n",
        "    corr = CORR(pred, true)\n",
        "    rse = RSE(pred, true)\n",
        "\n",
        "\n",
        "    return mae, mse, rmse, mape, mspe, corr, rse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuyPJnp0CwfA"
      },
      "source": [
        "#Encoder_Scaled Attention_Decoder (Seq2Seq Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "stHcfCyDhGUx"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
        "        self.fc_hidden = nn.Linear(hidden_size * 2 * num_layers, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output_enc, (hidden, cell) = self.lstm(input)  # [batch, seq_len, 2*hidden_size]\n",
        "        hidden_1dim = self.fc_hidden(hidden.permute(1, 0, 2).reshape(hidden.shape[1], -1))  # [batch, hidden_size]\n",
        "        output_enc = self.dropout(output_enc)\n",
        "        return output_enc, hidden, cell, hidden_1dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xgcrtH5QhIY3"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.query = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.key = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.value = nn.Linear(2 * hidden_size, 2 * hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # LSTM and output layers\n",
        "        self.lstm = nn.LSTM(2 * hidden_size + output_size, hidden_size, num_layers=num_layers, bidirectional=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(2 * hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, encoder_state, hidden_decoder, cell_decoder, hidden_1dim):\n",
        "        # Prepare attention mechanism\n",
        "        query = self.query(encoder_state)  # [batch, seq_len, hidden_size]\n",
        "        key = self.key(encoder_state)      # [batch, seq_len, hidden_size]\n",
        "        value = self.value(encoder_state)  # [batch, seq_len, 2*hidden_size]\n",
        "\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.hidden_size ** 0.5)  # [batch, seq_len, seq_len]\n",
        "        attn_weights = nn.functional.softmax(scores, dim=-1)  # [batch, seq_len, seq_len]\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vector = torch.bmm(attn_weights, value)  # [batch, seq_len, 2*hidden_size]\n",
        "        context_vector = context_vector[:, -1, :].unsqueeze(1)  # [batch, 1, 2*hidden_size]\n",
        "\n",
        "        # Concatenate context vector with input\n",
        "        dec_input = torch.cat((context_vector, input.unsqueeze(1)), dim=2)  # [batch, 1, 2*hidden_size + output_size]\n",
        "\n",
        "        # LSTM step\n",
        "        output_dec, (hidden_decoder, cell_decoder) = self.lstm(dec_input.permute(1, 0, 2), (hidden_decoder, cell_decoder))\n",
        "        prediction = self.fc(output_dec.squeeze(0))  # [batch, output_size]\n",
        "\n",
        "        return prediction, hidden_decoder, cell_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "evI32Va9hMKW"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size, num_layers, dropout=0.1).to(device)\n",
        "        self.decoder = Decoder(hidden_size, output_size, num_layers, dropout=0.1).to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, target=None):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1] if target is not None else config['pred_len']\n",
        "        outputs = torch.zeros(target_len, batch_size, config['output_size']).to(self.device)\n",
        "\n",
        "        # Encoder pass\n",
        "        out_encoder, hidden, cell, hidden_1dim = self.encoder(source.float())\n",
        "\n",
        "        # Initialize decoder input\n",
        "        dec_input = torch.zeros(batch_size, config['output_size']).to(self.device)  # Start token or zeros\n",
        "\n",
        "        for t in range(target_len):\n",
        "            teacher_forcing = torch.rand(1) < 0.5 if target is not None else False\n",
        "\n",
        "            if teacher_forcing and target is not None:\n",
        "                dec_input = target[:, t, :]  # Use ground truth as next input\n",
        "            else:\n",
        "                dec_input = outputs[t - 1] if t > 0 else dec_input  # Use previous prediction\n",
        "\n",
        "            # Decoder pass\n",
        "            prediction, hidden, cell = self.decoder(\n",
        "                dec_input, out_encoder, hidden, cell, hidden_1dim.unsqueeze(0)\n",
        "            )\n",
        "            outputs[t] = prediction\n",
        "\n",
        "        return outputs.permute(1, 0, 2)  # [batch, pred_len, output_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63fbAaaB0E0h"
      },
      "source": [
        "#Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AOlHxzYmzlwE"
      },
      "outputs": [],
      "source": [
        "momentum = 0 #0.9\n",
        "alpha = 0.99\n",
        "eps = 1e-08\n",
        "\n",
        "model = Seq2Seq(config['input_size'], config['hidden_size'], config['output_size'],\n",
        "                config['num_layers'], device).to(device)\n",
        "\n",
        "criteria = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = config['learning_rate'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K4WX6saW5tJ"
      },
      "source": [
        "# Test Phases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMz1mE9CXr7S",
        "outputId": "d3bccbe7-b0c6-4881-f782-1aa510c78c1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-63d6c593a390>:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  return torch.tensor(x), torch.tensor(y)#, torch.tensor(forecast)\n",
            "<ipython-input-25-a314eb2ad162>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test_fft = torch.fft.fft(torch.tensor(x_test))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x_test, y_test = MyCreate_dataset(test_data,config['seq_len'], config['pred_len'], config['output_size'], step = config['pred_len'])\n",
        "\n",
        "x_test_fft = torch.fft.fft(torch.tensor(x_test))\n",
        "\n",
        "x_test_fft = torch.real(x_test_fft)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_fft, y_test), shuffle=False , batch_size=1, drop_last= True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k42pIkt4J_a",
        "outputId": "ef542c09-ac98-4b2e-95f5-14b1fb5a0e41"
      },
      "outputs": [],
      "source": [
        "# Weghit upload to GPU\n",
        "# model.load_state_dict(torch.load(model_weights_path))\n",
        "\n",
        "# Load model weights with map_location set to 'cpu'\n",
        "model.load_state_dict(torch.load(model_weights_path, map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0c0JiQJWSzF",
        "outputId": "729433c8-41cd-4fdf-eda1-aa5c4fef4227"
      },
      "outputs": [],
      "source": [
        "torch.cuda.memory_allocated(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "l6sD1f7_bIBh"
      },
      "outputs": [],
      "source": [
        "def test_new(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "\n",
        "    pred_torch = torch.empty(0)\n",
        "    true_torch = torch.empty(0)\n",
        "\n",
        "    pred_array = np.array([])\n",
        "    true_array = np.array([])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(tqdm(test_loader, desc='Test')):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data.float())\n",
        "            output = output.to(device)\n",
        "\n",
        "            loss = criterion(output.float(), target.float())\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            true_ = target.squeeze(0)\n",
        "            true_ = true_.transpose(0, 1)\n",
        "            true_torch = torch.cat((true_torch.to(device), true_.to(device)), dim=1)\n",
        "\n",
        "\n",
        "            pred_ = output.squeeze(0)\n",
        "            pred_ = pred_.transpose(0, 1)\n",
        "\n",
        "\n",
        "            pred_torch = torch.cat((pred_torch.to(device), pred_.to(device)), dim=1)\n",
        "\n",
        "            pred_array = np.concatenate((pred_array, pred_.cpu().numpy().flatten()))\n",
        "            true_array = np.concatenate((true_array, true_.cpu().numpy().flatten()))\n",
        "\n",
        "\n",
        "    tr_np = true_torch.to('cpu').numpy()\n",
        "    true_transposed = np.transpose(tr_np)\n",
        "    true_result = torch.from_numpy(true_transposed)\n",
        "\n",
        "    true_result = scaler.inverse_transform(true_result.to('cpu'))\n",
        "\n",
        "\n",
        "    pr_np = pred_torch.to('cpu').numpy()\n",
        "    pred_transposed = np.transpose(pr_np)\n",
        "    pred_result = torch.from_numpy(pred_transposed)\n",
        "\n",
        "    pred_result = scaler.inverse_transform(pred_result.to('cpu'))\n",
        "\n",
        "    true_result = np.transpose(true_result)\n",
        "    true_result = torch.tensor(true_result)\n",
        "    pred_result = np.transpose(pred_result)\n",
        "    pred_result = torch.tensor(pred_result)\n",
        "\n",
        "\n",
        "    torch.save(pred_result, model_weights_path_1 + pred_file)\n",
        "    torch.save(true_result, model_weights_path_1 + true_file)\n",
        "\n",
        "    print(\"pred_result = \", pred_result.shape)\n",
        "\n",
        "    mae, mse, rmse, mape, mspe , corr, rse = metric(pred_array, true_array)\n",
        "\n",
        "    print('\\n++++++++++++++++ Metrics +++++++++++++++++++++\\n')\n",
        "    print('MAE: {}, MSE: {}, RMSE: {}'.format(np.real(mae), np.real(mse), np.real(rmse)))\n",
        "    print(' MAPE: {}, MSPE: {}'.format( np.real(mape), np.real(mspe)))\n",
        "    print(' CORR: {}, RSE: {}'.format( np.real(corr), np.real(rse)))\n",
        "\n",
        "    return test_loss / len(test_loader), pred_torch, true_torch, mae, mse, rmse, mape, mspe , corr, rse ,true_result, pred_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3jx-_QVbIBi",
        "outputId": "339facf5-eb6e-4887-ffa2-ca0ab22bd53f"
      },
      "outputs": [],
      "source": [
        "avg_loss, pred_torch, true_torch, mae, mse, rmse, mape, mspe , corr, rse ,true_result, pred_result= test_new(model, test_loader, criteria, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GlOkxM_f7_7",
        "outputId": "77dd3846-5c4f-46d5-8c58-90366ef7d8db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running is finished\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = model_weights_path_1\n",
        "if not os.path.exists(folder_path):\n",
        "  os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "#ae, mse, rmse, mape, mspe\n",
        "str_mtr =\"___________________________\\n\"\n",
        "str_mtr += \"num_epoch = \" + str(config['epochs']) + \" , batch_size = \"+ str(config['batch_size']) + \",\\n seq_len = \" + str(config['seq_len']) + \" , pred_len = \" + str(config['pred_len']) +\"\\n\"\n",
        "str_mtr += \" num_layers_encoder = \" + str(config['num_layers']) + \" , hidden_size = \" + str(config['hidden_size']) + \" , learning_rate =\" + str(config['learning_rate']) +\"\\n\\n\"\n",
        "str_mtr += 'MAE = ' + str(mae) + '\\n' + 'MSE = '+ str(mse) + '\\n'+ 'RMSE = ' + str(rmse) + '\\n'+ 'MAPE = ' + str(mape) + '\\n'+ 'MSPE = ' + str(mspe)+\"\\n\"\n",
        "str_mtr += 'CORR = ' + str(corr) + '\\n' + 'RSE = '+ str(rse)\n",
        "\n",
        "with open( folder_path+Result_name, 'a') as f:\n",
        "  f.write(str_mtr)\n",
        "  f.write('\\n*******************\\n')\n",
        "  f.close()\n",
        "\n",
        "\n",
        "print(\"running is finished\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
