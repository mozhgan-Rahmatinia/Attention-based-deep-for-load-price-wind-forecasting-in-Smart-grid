{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4b-9cEw-AZZ"
      },
      "source": [
        "#imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtYF2q8b95P1",
        "outputId": "49b6ad94-fcdb-4e04-bccd-5f86b44cdf9b"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sDg_dJgk-EjY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler,RobustScaler\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9gKgkky-Gaq"
      },
      "source": [
        "#Config Dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zKAOpWSw-KEX"
      },
      "outputs": [],
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5SZ6VPES-P4d"
      },
      "outputs": [],
      "source": [
        "config = dotdict()\n",
        "\n",
        "config.input_size = 6 #(month, day,hour , ...)\n",
        "config.output_size = 3\n",
        "\n",
        "config.hidden_size = 256\n",
        "config.num_layers =2 \n",
        "\n",
        "config.seq_len = 96\n",
        "config.pred_len = 12\n",
        "\n",
        "config.random_seed= 1\n",
        "\n",
        "config.learning_rate = 0.001\n",
        "\n",
        "config.batch_size = 32\n",
        "config.epochs = 500\n",
        "\n",
        "\n",
        "\n",
        "config.early_stopping = 8\n",
        "config.Model = 'GB_MyModel_'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pElBTBtH-iAY"
      },
      "source": [
        "# Data\n",
        "### read, preprocess, split, scale, Create Daatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bjqrvcy2-eGs"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yin6U3bN-eDK",
        "outputId": "0911b3de-799a-42f0-9419-9f5228248142"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VKoZZKHX-s0g"
      },
      "outputs": [],
      "source": [
        "def Read_Data():\n",
        "\n",
        "  data = pd.read_csv('/content/drive/MyDrive/Data_FFT_Model/GB_GBN_withoutTemp_Wind.csv')\n",
        "\n",
        "  data['date'] = pd.to_datetime(data.date)\n",
        "  data['year'] = data['date'].dt.year\n",
        "  data['month'] = data['date'].dt.month\n",
        "  data['day'] = data['date'].dt.day\n",
        "  data['hour'] = data['date'].dt.hour\n",
        "\n",
        "  data = data.drop('date', axis=1)\n",
        "  data = data.drop('year', axis=1)\n",
        "\n",
        "  #DROP NULL\n",
        "  print('data_shape BEFORE drop null' ,data.shape)\n",
        "  #Remove Missing Values\n",
        "  data = data.dropna(axis=0, how='any')\n",
        "  print('data_shape AFTER drop null' ,data.shape)\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SzRxHoJH_c42"
      },
      "outputs": [],
      "source": [
        "def Data_Cleaning(data):\n",
        "\n",
        "  threshold = 2\n",
        "  print('first shape =',data.shape)\n",
        "\n",
        "  #Remove Noise and Outliers\n",
        "  data =data[(data['Price']>0)] \n",
        "  print('After prc remove = ', data.shape)\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z_0cb0ls_xkj"
      },
      "outputs": [],
      "source": [
        "def Data_Split_Scales(data, scale):\n",
        "  #split\n",
        "  train_size = int( len(data) * 0.8 )\n",
        "  test_size = len(data) - train_size\n",
        "  train, test = data[:train_size], data[train_size:]\n",
        "\n",
        "  #scale\n",
        "  if scale:\n",
        "    scaler = StandardScaler() #MinMaxScaler()#RobustScaler#Ÿè\n",
        "    train = scaler.fit_transform(train.values)\n",
        "    test = scaler.fit_transform(test.values)\n",
        "\n",
        "  return train, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhLMG1h6Ai2T",
        "outputId": "e7201c85-92c5-4165-d529-537cfaaa0a74"
      },
      "outputs": [],
      "source": [
        "data = Read_Data()\n",
        "data = Data_Cleaning(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FVlFh8uKApIa"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = Data_Split_Scales(data, scale =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3AVp6XGbA2g6"
      },
      "outputs": [],
      "source": [
        "train_data, eval_data = Data_Split_Scales(train_data, scale =False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C2copogc8A2m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnKnC3FBBTBj",
        "outputId": "d69c3eef-d945-42aa-f08f-b3db1c3e90ed"
      },
      "outputs": [],
      "source": [
        "print('train.shape :', train_data.shape)\n",
        "print('eval_data.shape :', eval_data.shape)\n",
        "print('test.shape :', test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hYq1aXufBZKF"
      },
      "outputs": [],
      "source": [
        "def MyCreate_dataset(data, seq_len, pred_len, pred_size, step):\n",
        "  x, y =[], []\n",
        "\n",
        "  for i in range(0, len(data) - seq_len - pred_len , step):\n",
        "    feature = data[i: i+seq_len]\n",
        "    target = data[i+seq_len: i+seq_len+pred_len]\n",
        "\n",
        "    target = target[:, 0:pred_size]\n",
        "\n",
        "\n",
        "    x.append(feature)\n",
        "    y.append(target)\n",
        "\n",
        "  return torch.tensor(x), torch.tensor(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuyPJnp0CwfA"
      },
      "source": [
        "#Encoder_Scaled Attention_Decoder (Seq2Seq Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "L7JgudvAC0KO"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
        "        self.fc_hidden = nn.Linear(hidden_size * 2 * num_layers, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output_enc, (hidden, cell) = self.lstm(input)  # [batch, seq_len, 2*hidden_size]\n",
        "        hidden_1dim = self.fc_hidden(hidden.permute(1, 0, 2).reshape(hidden.shape[1], -1))  # [batch, hidden_size]\n",
        "        output_enc = self.dropout(output_enc)\n",
        "        return output_enc, hidden, cell, hidden_1dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "vr3_5NWFC2uG"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.query = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.key = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.value = nn.Linear(2 * hidden_size, 2 * hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # LSTM and output layers\n",
        "        self.lstm = nn.LSTM(2 * hidden_size + output_size, hidden_size, num_layers=num_layers, bidirectional=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(2 * hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, encoder_state, hidden_decoder, cell_decoder, hidden_1dim):\n",
        "        # Prepare attention mechanism\n",
        "        query = self.query(encoder_state)  # [batch, seq_len, hidden_size]\n",
        "        key = self.key(encoder_state)      # [batch, seq_len, hidden_size]\n",
        "        value = self.value(encoder_state)  # [batch, seq_len, 2*hidden_size]\n",
        "\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.hidden_size ** 0.5)  # [batch, seq_len, seq_len]\n",
        "        attn_weights = nn.functional.softmax(scores, dim=-1)  # [batch, seq_len, seq_len]\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vector = torch.bmm(attn_weights, value)  # [batch, seq_len, 2*hidden_size]\n",
        "        context_vector = context_vector[:, -1, :].unsqueeze(1)  # [batch, 1, 2*hidden_size]\n",
        "\n",
        "        # Concatenate context vector with input\n",
        "        dec_input = torch.cat((context_vector, input.unsqueeze(1)), dim=2)  # [batch, 1, 2*hidden_size + output_size]\n",
        "\n",
        "        # LSTM step\n",
        "        output_dec, (hidden_decoder, cell_decoder) = self.lstm(dec_input.permute(1, 0, 2), (hidden_decoder, cell_decoder))\n",
        "        prediction = self.fc(output_dec.squeeze(0))  # [batch, output_size]\n",
        "\n",
        "        return prediction, hidden_decoder, cell_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "DyiMe0HsC56N"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size, num_layers, dropout=0.1).to(device)\n",
        "        self.decoder = Decoder(hidden_size, output_size, num_layers, dropout=0.1).to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, target=None):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1] if target is not None else config['pred_len']\n",
        "        outputs = torch.zeros(target_len, batch_size, config['output_size']).to(self.device)\n",
        "\n",
        "        # Encoder pass\n",
        "        out_encoder, hidden, cell, hidden_1dim = self.encoder(source.float())\n",
        "\n",
        "        # Initialize decoder input\n",
        "        dec_input = torch.zeros(batch_size, config['output_size']).to(self.device)  # Start token or zeros\n",
        "\n",
        "        for t in range(target_len):\n",
        "            teacher_forcing = torch.rand(1) < 0.5 if target is not None else False\n",
        "\n",
        "            if teacher_forcing and target is not None:\n",
        "                dec_input = target[:, t, :]  # Use ground truth as next input\n",
        "            else:\n",
        "                dec_input = outputs[t - 1] if t > 0 else dec_input  # Use previous prediction\n",
        "\n",
        "            # Decoder pass\n",
        "            prediction, hidden, cell = self.decoder(\n",
        "                dec_input, out_encoder, hidden, cell, hidden_1dim.unsqueeze(0)\n",
        "            )\n",
        "            outputs[t] = prediction\n",
        "\n",
        "        return outputs.permute(1, 0, 2)  # [batch, pred_len, output_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63fbAaaB0E0h"
      },
      "source": [
        "#Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "AOlHxzYmzlwE"
      },
      "outputs": [],
      "source": [
        "momentum = 0 #0.9\n",
        "alpha = 0.99\n",
        "eps = 1e-08\n",
        "\n",
        "model = Seq2Seq(config['input_size'], config['hidden_size'], config['output_size'],\n",
        "                config['num_layers'], device).to(device)\n",
        "\n",
        "criteria = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = config['learning_rate'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grt0fbZa0HNZ"
      },
      "source": [
        "#train phases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQk6rSZL6rtz",
        "outputId": "d89dda2f-aa45-44b1-e618-bb88635df8e9"
      },
      "outputs": [],
      "source": [
        "torch.cuda.memory_allocated(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Saf9sC5JoxM7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)          # for numpy\n",
        "    random.seed(seed)             # for random \n",
        "    torch.manual_seed(seed)       # for PyTorch (CPU)\n",
        "    torch.cuda.manual_seed(seed)  # for PyTorch (GPU)\n",
        "    torch.cuda.manual_seed_all(seed)  #for Multi GPU\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN\n",
        "    torch.backends.cudnn.benchmark = False     # CuDNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "ERmexPCWozfQ"
      },
      "outputs": [],
      "source": [
        "Random_seed = config['random_seed']\n",
        "set_seed(Random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlAPhd3SCFuX",
        "outputId": "dd99e9d8-bc39-4cb6-d328-fdb85b92e783"
      },
      "outputs": [],
      "source": [
        "#Train ______________\n",
        "x_train, y_train = MyCreate_dataset(train_data, config['seq_len'], config['pred_len'], config['output_size'], step=1)\n",
        "print('x_train :' , x_train.shape)\n",
        "print('y_train :' , y_train.shape)\n",
        "\n",
        "x_train_fft = torch.fft.fft(torch.tensor(x_train))\n",
        "\n",
        "x_train_fft = torch.real(x_train_fft)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(x_train_fft, y_train),\n",
        "    shuffle=True,\n",
        "    batch_size=config['batch_size'],\n",
        "    drop_last=True,\n",
        "    num_workers=0,\n",
        "    worker_init_fn=lambda _: np.random.seed(Random_seed)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa9SOusDRhmK",
        "outputId": "c489ab34-4ca4-4309-e73b-d92144a56af3"
      },
      "outputs": [],
      "source": [
        "#Eval ______________\n",
        "x_eval, y_eval = MyCreate_dataset(eval_data, config['seq_len'], config['pred_len'], config['output_size'], step=1)\n",
        "print('x_eval :' , x_eval.shape)\n",
        "print('y_eval :' , y_eval.shape)\n",
        "\n",
        "x_eval_fft = torch.fft.fft(torch.tensor(x_eval))\n",
        "\n",
        "x_eval_fft = torch.real(x_eval_fft)\n",
        "\n",
        "\n",
        "eval_dataloader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(x_eval_fft, y_eval),\n",
        "    shuffle=True,\n",
        "    batch_size=config['batch_size'],\n",
        "    drop_last=True,\n",
        "    num_workers=0,\n",
        "    worker_init_fn=lambda _: np.random.seed(Random_seed)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFRO8pv1lJMr"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "5u1cZWxnOcqb"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    val_losses = []\n",
        "    train_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    stop_cheack = 0\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        print('\\n********************\\n')\n",
        "        train_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc='Train')):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data.float(), target.float())\n",
        "            output = output.to(device)\n",
        "\n",
        "            loss = criterion(output.float(), target.float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            train_loss_2 = train_loss / len(train_loader)\n",
        "\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(tqdm(val_loader, desc='Validating')):\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data.float(), target.float())\n",
        "                output = output.to(device)\n",
        "                val_loss += criterion(output.float(), target.float()).item()\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "        # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            filename = f\"{config['Model']}_seed_pred {config['pred_len']}_{config['random_seed']}_ep {epoch}_seq {config['seq_len']}.pth\"\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/Data_FFT_Model/MyModel_4Esfand1403/'+ filename)\n",
        "            stop_cheack = 0\n",
        "        else:\n",
        "          stop_cheack += 1\n",
        "\n",
        "        print('==========================')\n",
        "        print(f\"Epoch {epoch}/{config['epochs']}:  \\n Train Loss: {train_loss:.4f}, tain Loss scale = {train_loss_2:.4},  Val Loss: {val_loss:.4f}\")\n",
        "        print('_____________\\n', '\\nAvg _train_Loss =', train_loss / len(train_loader), '\\nAvg_val_loss =', val_loss)\n",
        "        los_ = train_loss / len(train_loader)\n",
        "        train_losses.append(los_)\n",
        "\n",
        "        # Check early stopping criteria\n",
        "        if stop_cheack >= config['early_stopping']:\n",
        "            print(\"****************** Early stopping *************************\")\n",
        "            print(f\"Epoch {epoch+1}/{config['epochs']}\")\n",
        "            break\n",
        "\n",
        "    # Plot train and validation losses\n",
        "    plt.plot(train_losses, label='Train loss')\n",
        "    plt.plot(val_losses, label='Validation loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    return train_loss / len(train_loader), train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du87wOw2SGPI",
        "outputId": "9a97013e-129b-4f37-f518-6794df4672ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "avg_loss, loss_array , val_losses= train(model, train_dataloader, eval_dataloader, criteria, optimizer, device)\n",
        "print('------------------- train is complete -------------------------')\n",
        "print('avg_loss =' , avg_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ4OBi-dGS6n"
      },
      "outputs": [],
      "source": [
        "losses_cpu = torch.tensor(loss_array, device='cuda').cpu()#.tolist()\n",
        "val_losses_cpu = torch.tensor(val_losses, device='cuda').cpu()#.tolist()\n",
        "\n",
        "\n",
        "# ÿ±ÿ≥ŸÖ ŸÜŸÖŸàÿØÿßÿ± ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÑÿßÿ≥ ÿØÿ± Ÿáÿ± ŸÖÿ±ÿ≠ŸÑŸá\n",
        "plt.plot(losses_cpu)\n",
        "plt.plot(val_losses_cpu)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OZyf86_JXfS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
